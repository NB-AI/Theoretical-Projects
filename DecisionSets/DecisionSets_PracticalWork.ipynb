{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                        Practical Work in AI - updated version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with paper \"Computing Optimal Decision Sets with SAT\" \"4.1 Iterative SAT Model\" (Yu et al., 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Nina Braunmiller k11923286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. Imports<br>\n",
    "<br>\n",
    "1.  Function implementation<br>\n",
    "1.a. Create Decision Set Classifier<br>\n",
    "1.b. Functions for working with data sets<br>\n",
    "<br>\n",
    "2. Working with data set example from \"Computing Optimal Decision Sets with SAT\" page 4<br>\n",
    "<br>\n",
    "3. Two data sets from the internet <br>\n",
    "3.a. binary data set<br>\n",
    "3.b. recruitment data<br>\n",
    "<br>\n",
    "4. Working closer with the Mushroom data set<br>\n",
    "4.a. Convert the discrete data set into a binary one<br>\n",
    "4.b. Try out the classifiers for full data set<br>\n",
    "4.c. Use classifiers for reduced data set<br>\n",
    "4.d. Trying out if our decision set classifier can effectively learn from RIPPER's used features<br>\n",
    "<br>\n",
    "5. Final words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short remark: The aim of the notebook is to implement the decision set classifier (see 1.a.). It is in short described by 'dsc' or 'opt' like in the underlying paper.<br>\n",
    "You also have to install the KISSAT solver (https://github.com/arminbiere/kissat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyeda\n",
    "\n",
    "from pyeda.inter import *\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from prettytable import PrettyTable \n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold # train_test_split\n",
    "\n",
    "import sys # for extending recursion depth\n",
    "\n",
    "# pip install wittgenstein\n",
    "import wittgenstein as lw # for using RIPPER\n",
    "\n",
    "from collections import Counter # to count elements in a string\n",
    "\n",
    "import os # to find the path of our used solver kissat\n",
    "\n",
    "from sklearn.utils import shuffle # to shuffle a data array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend recursion depth\n",
    "sys.setrecursionlimit(80000) # 10000 is an example, try with different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'sys' (built-in)> : \n",
      "your version  3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0] \n",
      "originally used version  3.7.3 \n",
      "\n",
      "<module 'pyeda' from '/home/c/anaconda3/lib/python3.7/site-packages/pyeda/__init__.py'> : \n",
      "your version  0.28.0 \n",
      "originally used version  0.28.0 \n",
      "\n",
      "<module 'numpy' from '/home/c/anaconda3/lib/python3.7/site-packages/numpy/__init__.py'> : \n",
      "your version  1.19.2 \n",
      "originally used version  1.19.2 \n",
      "\n",
      "<module 're' from '/home/c/anaconda3/lib/python3.7/re.py'> : \n",
      "your version  2.2.1 \n",
      "originally used version  2.2.1 \n",
      "\n",
      "<module 'pandas' from '/home/c/anaconda3/lib/python3.7/site-packages/pandas/__init__.py'> : \n",
      "your version  1.1.4 \n",
      "originally used version  1.1.4 \n",
      "\n",
      "<module 'matplotlib' from '/home/c/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py'> : \n",
      "your version  3.3.2 \n",
      "originally used version  3.3.2 \n",
      "\n",
      "<module 'prettytable' from '/home/c/anaconda3/lib/python3.7/site-packages/prettytable/__init__.py'> : \n",
      "your version  3.0.0 \n",
      "originally used version  3.0.0 \n",
      "\n",
      "<module 'sklearn' from '/home/c/anaconda3/lib/python3.7/site-packages/sklearn/__init__.py'> : \n",
      "your version  0.23.2 \n",
      "originally used version  0.23.2 \n",
      "\n",
      "<module 'wittgenstein' from '/home/c/anaconda3/lib/python3.7/site-packages/wittgenstein/__init__.py'> : \n",
      "your version  0.3.2 \n",
      "originally used version  0.3.2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the used versions of imports:\n",
    "import matplotlib, prettytable \n",
    "import_list = [sys, pyeda, np, re, pd, matplotlib, prettytable, sklearn, lw] # sys gives us the python version\n",
    "my_versions = ['3.7.3','0.28.0','1.19.2','2.2.1','1.1.4','3.3.2','3.0.0','0.23.2','0.3.2']\n",
    "for ele, my_version in zip(import_list, my_versions):\n",
    "    try:\n",
    "        v = ele.__version__\n",
    "        print\n",
    "    except:\n",
    "        try:\n",
    "            v = ele.version\n",
    "            \n",
    "        except:\n",
    "            v = 'cant say version'\n",
    "    print(ele, ': \\nyour version ', v, '\\noriginally used version ', my_version, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Function implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a. Create Decision Set Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0) \n",
    "\n",
    "class DecisionSetClassifier:\n",
    "    '''\n",
    "    learns a decision/rule set which will then used to classify binary test data labels,\n",
    "    implemented after the paper \"Computing Optimal Decision Sets with SAT\" by Yu, Ignatiev, Stuckey, Bodic, 2020\n",
    "    chapter of the relating paper: \"4.1 Iterative SAT Model\" from where we implement the constraints (1)-(6);\n",
    "    paper describes that classifier also as \"opt\".\n",
    "    This classifier works for binary data sets (features and labels have to be binary)  \n",
    "    \n",
    "    general idea:\n",
    "    a chain of nodes are a rule iff it ends with a node containing the label feature. \n",
    "    a decision/rule set can contain several rules. The order of these rules doesn't matter.\n",
    "    a sample is classified by majority vote. When we have a tie the relating sample gets a class prediction of\n",
    "    the most common class within the train set.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, number_nodes):\n",
    "        # user needs to give the number of nodes which are part of the rules (decision set size):\n",
    "        self.number_nodes = number_nodes\n",
    "        \n",
    "        # Independent of user input:\n",
    "        self.most_common_class = None\n",
    "        \n",
    "        self.s_feat = None\n",
    "        self.s_mask = None\n",
    "        \n",
    "        self.t_array = None\n",
    "        self.t_array_for_prediction = None\n",
    "        \n",
    "        self.prediction_array = None\n",
    "        \n",
    "        self.data_shape = None # is needed for ruleset visualization\n",
    "        \n",
    "        self.list_number_samples_per_rule = [] # the index refers to the current rule in the decision set;\n",
    "        # here we look how many test set samples are fulfilled by the single rules\n",
    "\n",
    "        self.falsely_classified_list = [] # indices belong to the single rules of decision set;\n",
    "        # how many test set samples fulfill the rule conditions but are misclassified (locally, not globally)\n",
    "    \n",
    "    def reset(self):\n",
    "        ''' call this method when we want to create a new instance without information left from the old instance '''\n",
    "        \n",
    "        self.most_common_class = None\n",
    "        \n",
    "        self.s_feat = None\n",
    "        self.s_mask = None\n",
    "        \n",
    "        self.t_array = None\n",
    "        self.t_array_for_prediction = None\n",
    "        \n",
    "        self.prediction_array = None\n",
    "        \n",
    "        self.data_shape = None # is needed for ruleset visualization\n",
    "        \n",
    "        self.list_number_samples_per_rule = [] # the index refers to the current rule in the decision set;\n",
    "        # here we look how many test set samples are fulfilled by the single rules\n",
    "\n",
    "        self.falsely_classified_list = [] # indices belong to the single rules of decision set;\n",
    "        # how many test set samples fulfill the rule conditions but are misclassified (locally, not globally)\n",
    "        \n",
    "    def fit(self, data, path_to_kissat_solver = '/home/c/kissat/build/kissat'):\n",
    "        '''data includes targets (last column) here!;\n",
    "        data is training data;\n",
    "        with the fit method we want to learn rules from given training set, the method contains all needed \n",
    "        constraints \n",
    "        \n",
    "        For this method we worked with the package pyeda which can convert strings into expressions such that \n",
    "        the string elements are usable to work with SAT, e. g. transforming into DIMACS.\n",
    "        '''\n",
    "        try: \n",
    "        \n",
    "            self.data_shape = data.shape # is needed for ruleset visualization\n",
    "\n",
    "            ####################################################\n",
    "            # PREPARATIONS OF VARIABLES FOR CLASSIFIER\n",
    "\n",
    "            # get most common class in train set which is later needed for prediction:\n",
    "            y_train = data[:,-1] \n",
    "            bins_counts = np.bincount(y_train)\n",
    "            self.most_common_class = np.argmax(bins_counts)\n",
    "\n",
    "\n",
    "            # initialize variables later needed:\n",
    "            number_features = data.shape[1]-1 # class is no feature here\n",
    "            number_examples = data.shape[0]\n",
    "\n",
    "            # create the s_jr variables:\n",
    "            matrix = exprvars('s',self.number_nodes,number_features+1) # +1 because we want nodes for the class\n",
    "\n",
    "\n",
    "            ####################################################\n",
    "            # CONSTRAINT 1\n",
    "            # we only have one feature per node\n",
    "\n",
    "            cond1_str = '('\n",
    "\n",
    "            for ind, single_nodes in enumerate(matrix[:-1]): # [:-1] because of condtion 2 we already know the which \n",
    "                # feature will be at node 11. Therefore, we ignore node 11 here.\n",
    "                single_state_all_features = '('\n",
    "                single_state_all_features_list = []\n",
    "                for ind2,s in enumerate(single_nodes):\n",
    "                    if ind2 != 0:\n",
    "                        single_state_all_features += ' | '\n",
    "                    single_state_all_features += str(s)\n",
    "                    single_state_all_features_list.append(s)\n",
    "                single_state_all_features += ')'\n",
    "\n",
    "                string_excluding = ''\n",
    "                for ind3, ele3 in enumerate(single_state_all_features_list):\n",
    "                    if ind3 < len(single_state_all_features_list)-1:\n",
    "                        for ind4, ele4 in enumerate(single_state_all_features_list[ind3+1:]):\n",
    "                            string_excluding += f' & (~{ele3} | ~{ele4})'\n",
    "                            \n",
    "                string_one_node = '(' + single_state_all_features + string_excluding + ')'\n",
    "                cond1_str += string_one_node\n",
    "                \n",
    "                if ind < len(matrix[:-1]) -1:\n",
    "                    cond1_str += ' & '\n",
    "                    \n",
    "            cond1_str += ')'\n",
    "\n",
    "            cond1_func = expr(cond1_str)\n",
    "            print('CONSTRAINT 1 done')\n",
    "\n",
    "            ####################################################\n",
    "            # CONSTRAINT 2\n",
    "            # the last node is always a leaf\n",
    "\n",
    "            cond2_last_node = exprvar('s',(self.number_nodes-1,number_features+1-1)) # -1 because we start at index 0\n",
    "            print('CONSTRAINT 2 done')\n",
    "\n",
    "            ####################################################\n",
    "            # CONSTRAINT 3\n",
    "            # at the first node all samples are true\n",
    "\n",
    "            cond3_expr = exprvars('v',number_examples,1) # 0 stands for 0-th node\n",
    "            cond3_str = ''\n",
    "            for ele in cond3_expr:\n",
    "                if cond3_str == '':\n",
    "                    cond3_str += str(ele[0])\n",
    "                else:\n",
    "                    cond3_str += f'&{ele[0]}'\n",
    "            cond3_func = expr(cond3_str)\n",
    "            print('CONSTRAINT 3 done')\n",
    "\n",
    "            ####################################################\n",
    "            # CONSTRAINT 4 + 5 + 6 (have two loops in common)\n",
    "\n",
    "            # 4: a sample is valid iff the current node is the start of the next rule or the feature value \n",
    "            # of that sample matches with the feature truth value of the previous node\n",
    "\n",
    "            # 5: when a sample is valid at a leaf, it has the same label as the leaf node\n",
    "\n",
    "            # 6: for every sample we have a leaf literal where the sample is valid\n",
    "\n",
    "            # constraints 4, 5, 6 share same loop.\n",
    "\n",
    "            cond4_str = ''\n",
    "            cond5_str = ''\n",
    "            cond6_str = '('\n",
    "\n",
    "            for ind_ex in range(number_examples):\n",
    "\n",
    "                if ind_ex != 0:\n",
    "                    cond6_str += ')&('\n",
    "\n",
    "                for ind_node in range(self.number_nodes):\n",
    "\n",
    "                    # feat_str part of constraint 4:\n",
    "                    feat_str = '('\n",
    "                    for ind_feat in range(number_features): \n",
    "                        if feat_str != '(':\n",
    "                            feat_str += '|'\n",
    "                        feat_str += f'(s[{ind_node},{ind_feat}] & Equal(t[{ind_node}], {data[ind_ex,ind_feat]}))'\n",
    "\n",
    "                    feat_str += ')'\n",
    "                    if ind_node < self.number_nodes-1: # loop stops for condition 4 one earlier than for 5,6\n",
    "                        if cond4_str != '':\n",
    "                            cond4_str += '&'\n",
    "\n",
    "                        cond4_str += f'(v[{ind_ex},{ind_node+1}] <=> s[{ind_node},{number_features}] | (v[{ind_ex},{ind_node}] & {feat_str}))'\n",
    "\n",
    "                    if cond5_str != '':\n",
    "                        cond5_str += '&' \n",
    "                    cond5_str += f'((s[{ind_node},{number_features}] & v[{ind_ex},{ind_node}]) => Equal(t[{ind_node}], {data[ind_ex,-1]}))'\n",
    "\n",
    "                    if ind_node != 0:\n",
    "                        cond6_str += '|'\n",
    "                    cond6_str += f'(s[{ind_node},{number_features}] & v[{ind_ex},{ind_node}])'\n",
    "\n",
    "            cond6_str += ')'    \n",
    "\n",
    "            cond4_func = expr(cond4_str)\n",
    "            print('CONSTRAINT 4 done')\n",
    "\n",
    "            cond5_func = expr(cond5_str)  \n",
    "            print('CONSTRAINT 5 done')\n",
    "\n",
    "            cond6_func = expr(cond6_str)\n",
    "            print('CONSTRAINT 6 done')\n",
    "\n",
    "            ####################################################\n",
    "            # PUTTING THE CONSTRAINTS TOGETHER AND GET A MODEL WITH HELP OF TSEITIN\n",
    "            sat_str = cond1_str + '&' + str(cond2_last_node) + '&' + cond3_str + '&' + cond4_str + '&' + cond5_str + '&' + cond6_str\n",
    "            print('final string done')\n",
    "            sat_func = expr(sat_str)\n",
    "            print('expressing string done')\n",
    "\n",
    "            sat_func_tsei = sat_func.tseitin() # to_cnf() also possible but far more complex, too long, is\n",
    "            # exponential sized\n",
    "            print('tseitin transformation done')\n",
    "\n",
    "            # Convert tseitin formula into the DIMACS format which is needed to feed the kissat solver which \n",
    "            # isn't included in our used package pyeda:\n",
    "            sat_func_tsei_dimacs = pyeda.boolalg.expr.expr2dimacscnf(sat_func_tsei)[1] \n",
    "            # [0]: we get the variable mapping\n",
    "\n",
    "            print('dimacs conversion done')\n",
    "\n",
    "\n",
    "\n",
    "            # Store the DIMACS formula in a file:\n",
    "            file = open('my_cnf.cnf', 'w')\n",
    "            file.write(f'{sat_func_tsei_dimacs}')\n",
    "            file.close()\n",
    "\n",
    "\n",
    "\n",
    "            # With jupyter notebook we have the opportunity to run command lines within the notebook by simply \n",
    "            # using:\n",
    "            # ! command line\n",
    "            # Let's use the command line here to solve the DIMACS format with the kissat solver which was\n",
    "            # downloaded from github (https://github.com/arminbiere/kissat): \n",
    "\n",
    "            path_including_kissat = path_to_kissat_solver #os.path.relpath(\"kissat\") # getting path to kissat solver when using same directory\n",
    "\n",
    "            out_with_linereading = ! '{path_including_kissat}' my_cnf.cnf #/home/c/kissat/build/add4.cnf\n",
    "\n",
    "            in1 = out_with_linereading.index('c ---- [ result ] ------------------------------------------------------------')\n",
    "            in2 = out_with_linereading.index('c ---- [ profiling ] ---------------------------------------------------------')\n",
    "\n",
    "            result_list = out_with_linereading[in1+1:in2]\n",
    "            sol_string = ' '.join(result_list)\n",
    "            list_literals = re.findall(r'-?\\d+', sol_string) # find all digits independent of sign\n",
    "\n",
    "            if list_literals == []: # we have no literals because there is no model\n",
    "                return None\n",
    "\n",
    "            list_literals.remove('0') # the 0 only marks the end of clauses in DIMACS\n",
    "\n",
    "            # Let's have a look at our mapping of expression symbols to natural numbers \n",
    "            # (change happend when formula was converted into DIMACS):\n",
    "            dimacs_mapping_dict = pyeda.boolalg.expr.expr2dimacscnf(sat_func_tsei)[0]         \n",
    "\n",
    "\n",
    "            ####################################################\n",
    "            # When using PICOSAT\n",
    "            '''\n",
    "            # When we don't use the KISSAT solver than we can make use of the in pyeda implemented PICOSAT solver.\n",
    "            # This solver doesn't need the DIMACS format. However, it is slower than the KISSAT solver.:\n",
    "            sat_model = sat_func_tsei.satisfy_one() # uses PICOSAT\n",
    "            if sat_model is None: # finding no model with PICOSAT\n",
    "                return None\n",
    "\n",
    "            # Find the variables in the model which are used/true:\n",
    "\n",
    "            s_array = np.array([0]*self.number_nodes, dtype=str)\n",
    "            t_array = np.array([0]*self.number_nodes)\n",
    "\n",
    "            for k,v in sat_model.items(): \n",
    "                if v==1 and ('aux' not in str(k)) and ('v' not in str(k)) and ('t' not in str(k)):\n",
    "                    node_index = int((re.findall(r'\\d+', str(k)))[0])\n",
    "                    used_feat_ = (re.findall(r'\\d+', str(k)))[1]\n",
    "                    s_array[node_index] = used_feat_\n",
    "                        \n",
    "                if v==1 and ('aux' not in str(k)) and ('v' not in str(k)) and ('s' not in str(k)):\n",
    "                    node_index = int((re.findall(r'\\d+', str(k)))[0])\n",
    "                    t_array[node_index] = 1\n",
    "                    \n",
    "            self.s_feat = s_array\n",
    "            self.t_array = t_array\n",
    "            '''\n",
    "            ####################################################\n",
    "\n",
    "            print('finding model done')\n",
    "\n",
    "\n",
    "\n",
    "            ####################################################\n",
    "            # PREPARE s_ARRAY AND t_ARRAY\n",
    "            # Here we want to collect all used features in order of the decision set. So, we collect from s_jr\n",
    "            # the r which stands for the feature index.\n",
    "            # Each node j can only carry one feature. This we want to filter.\n",
    "\n",
    "            # When using KISSAT instead of PICOSAT we get a slightly different model output description.\n",
    "            # Get all variables which are positive/used in our KISSAT model:\n",
    "\n",
    "            \n",
    "            s_array = np.array([0]*self.number_nodes, dtype=object)\n",
    "            t_array = np.array([0]*self.number_nodes)\n",
    "            \n",
    "            for single_literal in list_literals:\n",
    "\n",
    "                paper_variable = dimacs_mapping_dict[int(single_literal)] # paper_variable means the \n",
    "                # symbols used in the paper: s_jr, t_j, v_ij. \n",
    "                # v_ij describes the fitting of example i at node j. Ignore them for rule formulation.\n",
    "                \n",
    "                # Get all variables which appear in our final model of the formula:         \n",
    "                if ('~' not in str(paper_variable)) and ('aux' not in str(paper_variable)) and ('v' not in str(paper_variable)):\n",
    "                    \n",
    "                    # get all used s_jr variables our model and nothing else:\n",
    "                    if ('t' not in str(paper_variable)):\n",
    "                                                \n",
    "                        node_index = int((re.findall(r'\\d+', str(paper_variable)))[0]) \n",
    "                        # get all node indices j of s_jr\n",
    "                        \n",
    "                        used_feat_ = (re.findall(r'\\d+', str(paper_variable)))[1]\n",
    "                        \n",
    "                        # get all used features r of s_jr\n",
    "                        \n",
    "                        s_array[node_index] = used_feat_\n",
    "                        \n",
    "                    # get all positive t_j variables our model and nothing else:\n",
    "                    if ('s' not in str(paper_variable)):\n",
    "                        \n",
    "                        node_index = int((re.findall(r'\\d+', str(paper_variable)))[0])\n",
    "                        # get all node indices j of t_j\n",
    "                        \n",
    "                        t_array[node_index] = 1\n",
    "                        \n",
    "            self.t_array = t_array # collection of t_j ordered by node indices j\n",
    "            # at each node j where feature value = 1 we have in this array also a 1, else it is 0\n",
    "            \n",
    "            self.s_feat = s_array.astype(str) # collection of all used features r in order following node indices j \n",
    "            # retrieved from s_jr\n",
    "            \n",
    "            # Get indices of leaf nodes.\n",
    "            # That are the nodes in which the label feature is used instead of an other feature:\n",
    "            self.s_mask = np.where(self.s_feat==f'{data.shape[1]-1}') # data.shape[1]-1 gives our class\n",
    "\n",
    "            # modify t_array for creating the prediction array later:\n",
    "            self.t_array_for_prediction = np.copy(self.t_array) # without np.copy() self.t_array would become\n",
    "            # exactly the same object as self.t_array_for_prediction. Therefore, it would be modified when\n",
    "            # self.t_array_for_prediction would be modified.\n",
    "\n",
    "            self.t_array_for_prediction[np.where(self.t_array_for_prediction == 0)] = -1\n",
    "            # We need an extra array here because we will make majority vote for sample classifiaction later.\n",
    "\n",
    "\n",
    "            ####################################################\n",
    "\n",
    "            # DONE, we found a model. Therefore, 1 instead of None returned:\n",
    "            return 1\n",
    "        \n",
    "        except: # too high complexity to use code above\n",
    "            return -1 \n",
    "    \n",
    "    def predict(self, data, y_test=None): # here3\n",
    "        ''' data without labels, y_test needed for our evaluation of rules.\n",
    "        You can ignore it for samples for which the true label is unknown.'''\n",
    "        try:\n",
    "            y_test = np.copy(y_test) # else our global variable beyond the class y_test changes too with\n",
    "            # changes within this method\n",
    "        except: \n",
    "            pass\n",
    "        \n",
    "        old_ind = 0\n",
    "\n",
    "        number_test_samples = data.shape[0]\n",
    "        self.prediction_array = np.zeros((number_test_samples, ), dtype='int')\n",
    "        \n",
    "        for ind in self.s_mask[0]: # look at the single rules of our decision set, self.s_mask splits into single rules\n",
    "                        \n",
    "            # get the used features of one rule without the label \n",
    "            # because the label feature's index isn't needed at all:\n",
    "            s_feat_without_class = np.array(self.s_feat[old_ind:ind+1][:-1], dtype='int')\n",
    "           \n",
    "            data_small = data[:,s_feat_without_class] # only look at the features which were used by the rule\n",
    "  \n",
    "            # Now bring t_j into the game:\n",
    "            t_array_filtered_without_class = self.t_array[old_ind:ind+1][:-1] # getting the truth values \n",
    "            # for the used features of the current rule\n",
    "            \n",
    "            t_array_filtered_without_class = np.repeat(t_array_filtered_without_class.reshape(1,(len(t_array_filtered_without_class))), number_test_samples, axis=0)\n",
    "            # duplicate the line because below we will compare this array with the example array line by line\n",
    "           \n",
    "            \n",
    "            # Have a look at the filtered examples:\n",
    "            ex_fit_rule = np.all(data_small == t_array_filtered_without_class, axis=1) # compare sample by sample\n",
    "            # (row by row) if the single example fulfills the truth values which are given by the current rule\n",
    "            \n",
    "            if np.any(ex_fit_rule): # at least one sample fits to the current rule\n",
    "                \n",
    "                predicted_class_weight = self.t_array_for_prediction[old_ind:ind+1][-1] \n",
    "                # thats the truth value for the class of the current rule {-1/negative_class,1/positive_class}\n",
    "\n",
    "                # getting the examples which are part of the current class:\n",
    "                ind_of_fitting_ex = np.where(ex_fit_rule)\n",
    "                \n",
    "                self.prediction_array[ind_of_fitting_ex] += predicted_class_weight\n",
    "                \n",
    "                # this class weight is either 1 (class 1) or -1 (class 0). \n",
    "                # When look at all rules and every time when a rule fits to an example we get its prediction.\n",
    "                # However, this prediction doesn't have always be the same. \n",
    "                # By majority vote will be determined what the final prediction is. \n",
    "                # Therefore, we can simply add the weight every time a rule fits.\n",
    "                # When after the last rule the prediction is 0 the we choose the most common class as prediction.\n",
    "                # final prediction > 0 predicts 1, whereas prediction < 0 predicts 0.\n",
    "                \n",
    "                ########################################################################################\n",
    "                # only needed for evaluation purposes. no value for this method def predict.\n",
    "                if y_test is None: \n",
    "                    print('Be aware that we need y_test to make use of the table visualization of the method ruleset_performance.')\n",
    "                else:\n",
    "                    # count how many samples fit to the current rule:\n",
    "                    number_fitting_to_rule = len(ind_of_fitting_ex[0])\n",
    "                    self.list_number_samples_per_rule.append(number_fitting_to_rule)\n",
    "\n",
    "                    # count how many rules which fulfill rule conditions are misclassifications:\n",
    "                    y_test[np.where(y_test==0)] = -1\n",
    "                    number_falsely_classified = len(np.where(y_test[ind_of_fitting_ex] != predicted_class_weight)[0])\n",
    "                    self.falsely_classified_list.append(number_falsely_classified)\n",
    "                ########################################################################################\n",
    "                \n",
    "            else:\n",
    "                print('no sample for our rule fitting')\n",
    "                self.list_number_samples_per_rule.append(0)\n",
    "                self.falsely_classified_list.append(0)\n",
    "                \n",
    "            old_ind = ind + 1 \n",
    "\n",
    "        # convert prediction array to the classes we want to predict. Final prediction {0,1}:\n",
    "        self.prediction_array[np.where(self.prediction_array>0)] = 1\n",
    "        # sample was more often classified as positive than negative.\n",
    "\n",
    "        self.prediction_array[np.where(self.prediction_array==0)] = self.most_common_class \n",
    "        # a tie. Sample got the same amount of positive and negative label predictions or the sample doesn't\n",
    "        # fit to any rule. Then we predict the most common class in our training set.\n",
    "\n",
    "        self.prediction_array[np.where(self.prediction_array<0)] = 0\n",
    "        # sample was more often classified as negative than positive. For this purpose we needed the\n",
    "        # self.t_array_for_prediction which also contains negative values for the negative class 0.\n",
    "\n",
    "        return self.prediction_array\n",
    "   \n",
    "\n",
    "    def score(self, y_test):\n",
    "        ''' method predict has to be called before! \n",
    "        returns the accuracy'''\n",
    "        if self.prediction_array is None:\n",
    "            raise Exception('First call class.predict(data, y_test) !')\n",
    "        else:\n",
    "            correctly_predicted = len(np.where(self.prediction_array == y_test)[0])\n",
    "            acc = correctly_predicted / len(y_test) \n",
    "        return acc\n",
    "\n",
    "    \n",
    "    def ruleset_(self):\n",
    "        '''visualization decision set. usable after usage of method fit.\n",
    "        This method is also automatically used by method ruleset_performance.\n",
    "        \n",
    "        Aim: create a visualization of the found rules. For this destination simply use the already found out \n",
    "        '''\n",
    "        \n",
    "        if self.s_feat is None:\n",
    "            raise Exception('Call first class.fit(data)')\n",
    "            \n",
    "        # self.s_feat, self.t_array, self.s_mask which were found in the fit method:\n",
    "        s_feat = np.copy(self.s_feat)\n",
    "       \n",
    "        t_array = np.copy(self.t_array)\n",
    "        s_mask = np.copy(self.s_mask) # gives us the split of single rules by indices\n",
    "\n",
    "        # Replacing truth boolean values 0 and 1 by '' and '¬' for easier reading of ruleset later:\n",
    "        t_array = t_array.astype(str)\n",
    "        t_array[np.where(t_array=='1')] = ''\n",
    "        t_array[np.where(t_array=='0')] = '¬'\n",
    "\n",
    "        s_plus_t = np.char.add(t_array, s_feat) # s_feat combined with t_array. Needed below\n",
    "        \n",
    "        # Concatenate the used features by using 'and'/'^':\n",
    "        s_feat = np.char.add(s_feat, ' ∧ ') # with np.char.add() can we merge two strings elementwise in an array together\n",
    "\n",
    "        # Replace the class feature indices by the word 'class':\n",
    "        \n",
    "        s_feat = s_feat.astype(object) # needed to put 'class|' into array, when we would have dtype=str then\n",
    "        # 'class|' would be a too long element to put in (because longer than other elements)\n",
    "        s_feat[s_mask] = 'class|'\n",
    "        \n",
    "        s_feat = s_feat.astype(str) # for upcoming operations the array has to be of type str\n",
    "\n",
    "        # Adding t_array to s_feat:\n",
    "        s_feat = np.char.add(t_array, s_feat)\n",
    "       \n",
    "        # Feature directly in front of 'class' needs implication instead of conjunction:\n",
    "        s_feat[s_mask[0]-1] = np.char.add(s_plus_t[s_mask[0]-1], ' → ')\n",
    "        \n",
    "        rule_string = ''.join(s_feat.tolist()) # we want all rules as string without commas.\n",
    "        \n",
    "        return rule_string\n",
    "    \n",
    "    def ruleset_performance(self):\n",
    "        '''\n",
    "        This method can only be called after the methods fit and predict!\n",
    "        '''\n",
    "        \n",
    "        if self.list_number_samples_per_rule == []:\n",
    "            raise Exception('First call class.predict(data, y_test) !')\n",
    "        \n",
    "        rule_string = self.ruleset_()\n",
    "        list_rule_set = rule_string.split('|')[:-1]\n",
    "        \n",
    "        table = PrettyTable()\n",
    "        \n",
    "        # define the column names of our table:\n",
    "        columns = ['rules', '# test samples fulfilling rule conditions','# mistakenly fitting test samples', '% mistaken fits']\n",
    "        # Important: the column '% mistaken fits' doesn't talk about misclassifications but fitting of \n",
    "        # single samples to a certain rule although the ground truth label is different. \n",
    "        # Nevertheless, the sample can get the right prediction through majority vote.\n",
    "        \n",
    "        # add values to each of our columns:\n",
    "        table.add_column(columns[0], list_rule_set) # the rule visualization\n",
    "        table.add_column(columns[1], self.list_number_samples_per_rule)\n",
    "        table.add_column(columns[2], self.falsely_classified_list)\n",
    "        \n",
    "        # calculation of % of fitting samples with false ground truth label:\n",
    "        c = np.array(self.list_number_samples_per_rule)\n",
    "        percent_misclass = np.array(self.falsely_classified_list)/ c\n",
    "        percent_misclass[np.where(c==0)] = 0\n",
    "                \n",
    "        table.add_column(columns[3], percent_misclass )\n",
    "\n",
    "        \n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b. Functions for working with data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table to compare different classifiers:\n",
    "def tableizer(current_dataset_name:str , *row_values_lists):\n",
    "    ''' Create a table comparing our classifier with RIPPER. \n",
    "    argument row_values_lists has to be at least one list containing [info whether full data set used:str,\n",
    "    accuracy score our classifier, accuracy score RIPPER],\n",
    "    e. g. tableizer('data set jobs' ,['data set with shortend shape', 0.5, 0.1])'''\n",
    "    \n",
    "    table = PrettyTable(['data set forms','our decsision set classifier', 'RIPPER'])\n",
    "    table.title = 'best accuracy scores for data set ' + current_dataset_name\n",
    "     \n",
    "    for ind, ele in enumerate(row_values_lists):\n",
    "        table.add_row(ele)\n",
    "        \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates from data:\n",
    "def remove_duplicates(data_array):\n",
    "    ''' data_array has to be with y-column!\n",
    "    Remove all duplicates but also samples with same feature values but different labels (like it is done\n",
    "    in the underlying paper)'''\n",
    "    \n",
    "    # Remove ambiguous examples:\n",
    "    df = pd.DataFrame(data_array)\n",
    "    df1 = df.drop_duplicates() # remove all examples which are duplicates from each other (always one kept)\n",
    "    \n",
    "    df2 = df1.drop_duplicates(subset=[i for i in range((data_array[:,:-1]).shape[1])],keep=False)\n",
    "    # remove of examples with same features but different classes\n",
    "    data_array = df2.to_numpy(dtype='int')\n",
    "    \n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to implement stratified cross validation:\n",
    "def stratified_cross_validation(dataset, clf_ripper_dsc, number_folds=5,path_to_kissat_solver='/home/c/kissat/build/kissat'):\n",
    "    ''' number_folds=5 as used in the paper \n",
    "    '''\n",
    "    print('DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT')\n",
    "    \n",
    "    random.seed(0)\n",
    "\n",
    "    data = dataset.astype(int)\n",
    "\n",
    "    data = shuffle(data ,random_state=0) # bring examples into random order \n",
    "\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "\n",
    "    \n",
    "    skt = StratifiedKFold(n_splits=number_folds) # 5 folds were used by the paper\n",
    "\n",
    "    score_list = []\n",
    "    rule_list = []\n",
    "\n",
    "    for train_index, test_index in skt.split(X,y): \n",
    "        \n",
    "        clf = clf_ripper_dsc #lw.RIPPER() # Or irep_clf = lw.IREP() to build a model using IREP     \n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        if 'DecisionSetClassifier' in str(clf_ripper_dsc): \n",
    "            \n",
    "            data_train = np.concatenate((X_train, y_train.reshape(len(y_train),1)),axis=1) \n",
    "            # looks like the original data without the test set\n",
    "            # needed for the fit method that our array also has y lables included\n",
    "            \n",
    "            fitter = clf.fit(data_train, path_to_kissat_solver)\n",
    "\n",
    "            if fitter is None:\n",
    "                score = None\n",
    "                rule_set = None\n",
    "                \n",
    "            elif fitter == -1: # code couldn't be executed successfully\n",
    "                score = fitter\n",
    "                rule_set = None\n",
    "                \n",
    "            else:\n",
    "\n",
    "                clf.predict(X_test, y_test)\n",
    "                score = clf.score(y_test) \n",
    "                \n",
    "                rule_set = clf.ruleset_performance() # only working for our classifier, not ripper\n",
    "\n",
    "        else: # we use RIPPER\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            \n",
    "            # getting the rule set\n",
    "            # or use: print(ripper_clf.out_model())\n",
    "            # retrieved from: https://pypi.org/project/wittgenstein/\n",
    "            rule_set = clf.ruleset_ # ^ as 'and', V as 'or'  \n",
    "            \n",
    "        print('Reached score:', score)\n",
    "        score_list.append(score)    \n",
    "                \n",
    "\n",
    "        print('found ruleset:')        \n",
    "        print(rule_set) \n",
    "               \n",
    "        rule_list.append(str(rule_set))\n",
    "        \n",
    "        try: # our dsc used\n",
    "            clf.reset() # such that with upcoming instance we have no old information left\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    print(f'reached scores with {number_folds} folds:', score_list)   \n",
    "    \n",
    "    score_list.append(None) # so we can remove None below without error message when originally no None in list\n",
    "    score_list = set(score_list) # with help of the set() all None can be remove below\n",
    "    score_list.remove(None) # We get score None when our classifier can't find a model\n",
    "    \n",
    "    if len(score_list) > 0:\n",
    "        highest_score = max(score_list)\n",
    "    else:\n",
    "        highest_score = None\n",
    "    \n",
    "    \n",
    "    return highest_score, score_list, rule_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Working with data set example from \"Computing Optimal Decision Sets with SAT\" page 4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from underlying paper:\n",
    "data_array = np.array([[1,0,1,0,0],\n",
    "                    [1,0,0,1,0],\n",
    "                    [0,0,1,0,1],\n",
    "                    [1,1,0,0,0],\n",
    "                    [0,0,0,1,1],\n",
    "                    [1,1,1,1,0],\n",
    "                    [0,1,1,0,0],\n",
    "                    [0,0,1,1,1],\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try out whether our decision set classifier finds the same rules as in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 0 0 0]\n",
      " [0 0 0 1 1]\n",
      " [1 1 1 1 0]\n",
      " [0 1 1 0 0]\n",
      " [0 0 1 1 1]]\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "To predict the y labels we use the train data here because we only want to test if our descision set classifier is working.\n",
      "reached score: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>rules</th>\n",
       "            <th># test samples fulfilling rule conditions</th>\n",
       "            <th># mistakenly fitting test samples</th>\n",
       "            <th>% mistaken fits</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0 → ¬class</td>\n",
       "            <td>4</td>\n",
       "            <td>0</td>\n",
       "            <td>0.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>¬0 ∧ ¬1 → class</td>\n",
       "            <td>3</td>\n",
       "            <td>0</td>\n",
       "            <td>0.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1 → ¬class</td>\n",
       "            <td>3</td>\n",
       "            <td>0</td>\n",
       "            <td>0.0</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------------+-------------------------------------------+-----------------------------------+-----------------+\n",
       "|      rules      | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
       "+-----------------+-------------------------------------------+-----------------------------------+-----------------+\n",
       "|    0 → ¬class   |                     4                     |                 0                 |       0.0       |\n",
       "| ¬0 ∧ ¬1 → class |                     3                     |                 0                 |       0.0       |\n",
       "|    1 → ¬class   |                     3                     |                 0                 |       0.0       |\n",
       "+-----------------+-------------------------------------------+-----------------------------------+-----------------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array_opt = np.copy(data_array)\n",
    "\n",
    "X = data_array_opt[:,:-1]\n",
    "y = data_array_opt[:,-1]\n",
    "\n",
    "print(data_array_opt)\n",
    "\n",
    "dsc = DecisionSetClassifier(number_nodes = 7)\n",
    "\n",
    "fitter = dsc.fit(data_array_opt)\n",
    "\n",
    "dsc.ruleset_()\n",
    "\n",
    "dsc.predict(X,y)\n",
    "print('To predict the y labels we use the train data here because we only want to test if our descision set classifier is working.')\n",
    "\n",
    "score_dsc = dsc.score(y)\n",
    "print('reached score:', score_dsc)\n",
    "\n",
    "dsc.ruleset_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the column \"rules\" it for sure does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out RIPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875 score\n",
      "found rule set: \n",
      "[[0=0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_array_rip = data_array.astype(int)\n",
    "\n",
    "\n",
    "X = data_array_rip[:,:-1]\n",
    "y = data_array_rip[:,-1]\n",
    "\n",
    "ripper_clf = lw.RIPPER() # Or irep_clf = lw.IREP() to build a model using IREP\n",
    "\n",
    "ripper_clf.fit(X, y)\n",
    "\n",
    "score_ripper = ripper_clf.score(X, y)\n",
    "\n",
    "\n",
    "print(score_ripper, 'score')\n",
    "print('found rule set: ')\n",
    "ripper_rule_set = ripper_clf.ruleset_\n",
    "# getting the rule set\n",
    "# or use: print(ripper_clf.out_model())\n",
    "# retrieved from: https://pypi.org/project/wittgenstein/\n",
    "print(ripper_rule_set) # ^ as 'and', V as 'or'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <caption>best accuracy scores for data set from underlying paper</caption>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>data set forms</th>\n",
       "            <th>our decsision set classifier</th>\n",
       "            <th>RIPPER</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>full data set of shape (8, 5)</td>\n",
       "            <td>1.0</td>\n",
       "            <td>0.875</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------------------------------------------------------------------+\n",
       "|        best accuracy scores for data set from underlying paper        |\n",
       "+-------------------------------+------------------------------+--------+\n",
       "|         data set forms        | our decsision set classifier | RIPPER |\n",
       "+-------------------------------+------------------------------+--------+\n",
       "| full data set of shape (8, 5) |             1.0              | 0.875  |\n",
       "+-------------------------------+------------------------------+--------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableizer('from underlying paper' ,[f'full data set of shape {data_array.shape}', score_dsc, score_ripper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Two data sets from the internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a. binary data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"datasets\") / Path(\"research_gate_question\") / Path(\"SampleData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(data_dir, sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 751)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F742</th>\n",
       "      <th>F743</th>\n",
       "      <th>F744</th>\n",
       "      <th>F745</th>\n",
       "      <th>F746</th>\n",
       "      <th>F747</th>\n",
       "      <th>F748</th>\n",
       "      <th>F749</th>\n",
       "      <th>F750</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1  F2  F3  F4  F5  F6  F7  F8  F9  F10  ...  F742  F743  F744  F745  \\\n",
       "0     1   1   0   1   1   1   1   0   1    0  ...     0     0     1     0   \n",
       "1     1   1   0   1   1   1   1   0   1    0  ...     0     0     1     0   \n",
       "2     1   1   0   1   1   1   1   1   0    0  ...     0     0     0     0   \n",
       "3     1   1   0   1   1   1   1   1   0    0  ...     0     0     0     0   \n",
       "4     1   1   0   1   1   1   1   1   0    0  ...     0     0     0     0   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...   ...   ...   ...   ...   \n",
       "245   1   0   0   0   1   0   1   1   0    1  ...     0     0     1     0   \n",
       "246   1   0   0   0   1   0   1   1   0    1  ...     0     0     1     0   \n",
       "247   1   0   0   0   1   0   1   1   0    1  ...     0     0     1     0   \n",
       "248   1   0   0   0   1   0   1   1   0    1  ...     0     0     1     0   \n",
       "249   1   0   0   0   1   0   1   1   0    1  ...     0     0     1     0   \n",
       "\n",
       "     F746  F747  F748  F749  F750  class  \n",
       "0       1     1     1     1     0      1  \n",
       "1       1     1     1     1     0      1  \n",
       "2       1     0     1     1     0      1  \n",
       "3       1     0     1     1     0      1  \n",
       "4       1     0     1     1     0      1  \n",
       "..    ...   ...   ...   ...   ...    ...  \n",
       "245     1     1     1     0     1      1  \n",
       "246     1     1     1     0     1      1  \n",
       "247     1     1     1     0     1      1  \n",
       "248     1     1     1     0     1      1  \n",
       "249     1     1     1     0     1      1  \n",
       "\n",
       "[250 rows x 751 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns = [f'F{i}' for i in range(data_df.shape[1])]\n",
    "data_df['class'] = data_df['F0'].replace(['BAD','GOOD'], [0,1])\n",
    "del data_df['F0']\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    176\n",
       "0     74\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 751)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array_binary = data_df.to_numpy()\n",
    "data_array_binary = remove_duplicates(data_array_binary)\n",
    "data_array_binary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get started with stratisfied cross validation\n",
    "This is suitable for data set with uneven label distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest_score_binary_dsc, _, __ = stratified_cross_validation(data_array_binary, DecisionSetClassifier(number_nodes = 14), number_folds=5)\n",
    "# problem: jupyter notebook tells us that kernel dies\n",
    "highest_score_binary_dsc = 'computation too complex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "Reached score: 0.52\n",
      "found ruleset:\n",
      "[[182=0] V [233=1^21=1]]\n",
      "Reached score: 0.62\n",
      "found ruleset:\n",
      "[[458=0^384=0^158=1]]\n",
      "Reached score: 0.56\n",
      "found ruleset:\n",
      "[[182=0]]\n",
      "Reached score: 0.48\n",
      "found ruleset:\n",
      "[[396=0]]\n",
      "Reached score: 0.6\n",
      "found ruleset:\n",
      "[[182=0]]\n",
      "reached scores with 5 folds: [0.52, 0.62, 0.56, 0.48, 0.6]\n"
     ]
    }
   ],
   "source": [
    "highest_score_binary_ripper, _, __ = stratified_cross_validation(data_array_binary, lw.RIPPER(), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tableizer_binary1 = [f'full data set of shape {data_array_binary.shape}; #folds=5', highest_score_binary_dsc, highest_score_binary_ripper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**<br>\n",
    "-1: means that the problem was too complex for our decision set classifier. We can extend the recursion depth such that our classifier can make use of more computational ressources. This can be varied under: sys.setrecursionlimit(number)<br><br>\n",
    "None: means that our decision set classifier didn't find a model for our given data. A reason could be when training with small data sets and stratified cross validation, that there is indeed no pattern for which our classifier could find for a certain amount of rule nodes. We could increase the number of rule nodes 'number_nodes' (danger of too high complexity) and the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using shortened data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From shape (250, 751)\n",
      "To shape (59, 11)\n"
     ]
    }
   ],
   "source": [
    "print('From shape', data_array_binary.shape)\n",
    "data_array_binary_shortend = data_array_binary[:,740:]\n",
    "data_array_binary_shortend = remove_duplicates(data_array_binary_shortend)\n",
    "print('To shape', data_array_binary_shortend.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "reached scores with 5 folds: [None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "number_nodes = 28\n",
    "highest_score_binary_shortened_dsc,_,__ = stratified_cross_validation(data_array_binary_shortend, DecisionSetClassifier(number_nodes), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "Reached score: 0.5833333333333334\n",
      "found ruleset:\n",
      "[[0=0^6=1^7=1] V [8=1^2=0]]\n",
      "Reached score: 0.6666666666666666\n",
      "found ruleset:\n",
      "[[0=0^7=1^6=1]]\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "[[8=1]]\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "[[8=1^1=0] V [9=1] V [6=0^3=1]]\n",
      "Reached score: 0.6363636363636364\n",
      "found ruleset:\n",
      "[[6=1^0=0^7=1]]\n",
      "reached scores with 5 folds: [0.5833333333333334, 0.6666666666666666, 0.5, 0.5, 0.6363636363636364]\n"
     ]
    }
   ],
   "source": [
    "highest_score_binary_shortened_ripper,_,__ = stratified_cross_validation(data_array_binary_shortend, lw.RIPPER(), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tableizer_binary2 = [f'shortened data set of shape {data_array_binary_shortend.shape}; #folds=5', str(highest_score_binary_shortened_dsc)+f' with {number_nodes} nodes', highest_score_binary_shortened_ripper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize results in table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <caption>best accuracy scores for data set binary from internet</caption>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>data set forms</th>\n",
       "            <th>our decsision set classifier</th>\n",
       "            <th>RIPPER</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>full data set of shape (250, 751); #folds=5</td>\n",
       "            <td>computation too complex</td>\n",
       "            <td>0.62</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>shortened data set of shape (59, 11); #folds=5</td>\n",
       "            <td>None with 28 nodes</td>\n",
       "            <td>0.6666666666666666</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------------------------------------------------------------------------------------------------+\n",
       "|                       best accuracy scores for data set binary from internet                       |\n",
       "+------------------------------------------------+------------------------------+--------------------+\n",
       "|                 data set forms                 | our decsision set classifier |       RIPPER       |\n",
       "+------------------------------------------------+------------------------------+--------------------+\n",
       "|  full data set of shape (250, 751); #folds=5   |   computation too complex    |        0.62        |\n",
       "| shortened data set of shape (59, 11); #folds=5 |      None with 28 nodes      | 0.6666666666666666 |\n",
       "+------------------------------------------------+------------------------------+--------------------+"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableizer('binary from internet', list_tableizer_binary1, list_tableizer_binary2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**<br>\n",
    "-1: means that the problem was too complex for our decision set classifier. We can extend the recursion depth such that our classifier can make use of more computational ressources. This can be varied under: sys.setrecursionlimit(number)<br><br>\n",
    "None: means that our decision set classifier didn't find a model for our given data. A reason could be when training with small data sets and stratified cross validation, that there is indeed no pattern for which our classifier could find for a certain amount of rule nodes. We could increase the number of rule nodes 'number_nodes' (danger of too high complexity) and the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b. recruitment data\n",
    "This data is about job success and salary level. Originally it isn't binary. We only keep binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"datasets\") / Path(\"recuitment\") / Path(\"Placement_Data_Full_Class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(data_dir, sep=',')\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>status</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>91.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>58.80</td>\n",
       "      <td>Placed</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>79.33</td>\n",
       "      <td>Central</td>\n",
       "      <td>78.33</td>\n",
       "      <td>Others</td>\n",
       "      <td>Science</td>\n",
       "      <td>77.48</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>86.5</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>66.28</td>\n",
       "      <td>Placed</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>68.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Arts</td>\n",
       "      <td>64.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>57.80</td>\n",
       "      <td>Placed</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>56.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Science</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>59.43</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>85.80</td>\n",
       "      <td>Central</td>\n",
       "      <td>73.60</td>\n",
       "      <td>Central</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>73.30</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>96.8</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>55.50</td>\n",
       "      <td>Placed</td>\n",
       "      <td>425000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211</td>\n",
       "      <td>M</td>\n",
       "      <td>80.60</td>\n",
       "      <td>Others</td>\n",
       "      <td>82.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>77.60</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>91.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>74.49</td>\n",
       "      <td>Placed</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>M</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>60.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Science</td>\n",
       "      <td>72.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>53.62</td>\n",
       "      <td>Placed</td>\n",
       "      <td>275000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>M</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>73.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>Yes</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>69.72</td>\n",
       "      <td>Placed</td>\n",
       "      <td>295000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>F</td>\n",
       "      <td>74.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>66.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>60.23</td>\n",
       "      <td>Placed</td>\n",
       "      <td>204000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215</td>\n",
       "      <td>M</td>\n",
       "      <td>62.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Science</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>60.22</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sl_no gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p  \\\n",
       "0        1      M  67.00   Others  91.00   Others  Commerce     58.00   \n",
       "1        2      M  79.33  Central  78.33   Others   Science     77.48   \n",
       "2        3      M  65.00  Central  68.00  Central      Arts     64.00   \n",
       "3        4      M  56.00  Central  52.00  Central   Science     52.00   \n",
       "4        5      M  85.80  Central  73.60  Central  Commerce     73.30   \n",
       "..     ...    ...    ...      ...    ...      ...       ...       ...   \n",
       "210    211      M  80.60   Others  82.00   Others  Commerce     77.60   \n",
       "211    212      M  58.00   Others  60.00   Others   Science     72.00   \n",
       "212    213      M  67.00   Others  67.00   Others  Commerce     73.00   \n",
       "213    214      F  74.00   Others  66.00   Others  Commerce     58.00   \n",
       "214    215      M  62.00  Central  58.00   Others   Science     53.00   \n",
       "\n",
       "      degree_t workex  etest_p specialisation  mba_p      status    salary  \n",
       "0     Sci&Tech     No     55.0         Mkt&HR  58.80      Placed  270000.0  \n",
       "1     Sci&Tech    Yes     86.5        Mkt&Fin  66.28      Placed  200000.0  \n",
       "2    Comm&Mgmt     No     75.0        Mkt&Fin  57.80      Placed  250000.0  \n",
       "3     Sci&Tech     No     66.0         Mkt&HR  59.43  Not Placed       NaN  \n",
       "4    Comm&Mgmt     No     96.8        Mkt&Fin  55.50      Placed  425000.0  \n",
       "..         ...    ...      ...            ...    ...         ...       ...  \n",
       "210  Comm&Mgmt     No     91.0        Mkt&Fin  74.49      Placed  400000.0  \n",
       "211   Sci&Tech     No     74.0        Mkt&Fin  53.62      Placed  275000.0  \n",
       "212  Comm&Mgmt    Yes     59.0        Mkt&Fin  69.72      Placed  295000.0  \n",
       "213  Comm&Mgmt     No     70.0         Mkt&HR  60.23      Placed  204000.0  \n",
       "214  Comm&Mgmt     No     89.0         Mkt&HR  60.22  Not Placed       NaN  \n",
       "\n",
       "[215 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete non binary features:\n",
    "del data_df['sl_no']\n",
    "\n",
    "del data_df['ssc_p']\n",
    "del data_df['hsc_p']\n",
    "del data_df['degree_p']\n",
    "del data_df['etest_p']\n",
    "del data_df['mba_p']\n",
    "\n",
    "del data_df['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  ssc_b  hsc_b hsc_s degree_t  workex  specialisation  status\n",
       "0         0      0      1     1        0       0               0       1\n",
       "1         0      1      1     0        0       1               1       1\n",
       "3         0      1      0     0        0       0               0       0\n",
       "4         0      1      0     1        1       0               1       1\n",
       "5         0      0      1     0        0       1               1       0\n",
       "..      ...    ...    ...   ...      ...     ...             ...     ...\n",
       "210       0      0      1     1        1       0               1       1\n",
       "211       0      0      1     0        0       0               1       1\n",
       "212       0      0      1     1        1       1               1       1\n",
       "213       1      0      1     1        1       0               0       1\n",
       "214       0      1      1     0        1       0               0       0\n",
       "\n",
       "[197 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's code the binary feature into numeric one:\n",
    "data_df['gender'] = data_df['gender'].replace('M',0)\n",
    "data_df['gender'] = data_df['gender'].replace('F',1)\n",
    "\n",
    "data_df['ssc_b'] = data_df['ssc_b'].replace('Central',1)\n",
    "data_df['ssc_b'] = data_df['ssc_b'].replace('Others',0)\n",
    "\n",
    "data_df['hsc_s'] = data_df['hsc_s'].replace('Commerce',1)\n",
    "data_df['hsc_s'] = data_df['hsc_s'].replace('Science',0)\n",
    "values = [0,1]\n",
    "data_df = data_df[data_df.hsc_s.isin(values) == True]\n",
    "\n",
    "\n",
    "data_df['degree_t'] = data_df['degree_t'].replace('Comm&Mgmt',1)\n",
    "data_df['degree_t'] = data_df['degree_t'].replace('Sci&Tech',0)\n",
    "data_df = data_df[data_df.degree_t.isin(values) == True]\n",
    "\n",
    "data_df['specialisation'] = data_df['specialisation'].replace('Mkt&Fin',1)\n",
    "data_df['specialisation'] = data_df['specialisation'].replace('Mkt&HR',0)\n",
    "\n",
    "data_df['status'] = data_df['status'].replace('Placed',1)\n",
    "data_df['status'] = data_df['status'].replace('Not Placed',0)\n",
    "\n",
    "data_df['workex'] = data_df['workex'].replace('Yes',1)\n",
    "data_df['workex'] = data_df['workex'].replace('No',0)\n",
    "\n",
    "data_df['hsc_b'] = data_df['hsc_b'].replace('Others',1)\n",
    "data_df['hsc_b'] = data_df['hsc_b'].replace('Central',0)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array_job = data_df.to_numpy(dtype='int')\n",
    "data_array_job = remove_duplicates(data_array_job)\n",
    "data_array_job.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "reached scores with 5 folds: [None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "number_nodes = 29\n",
    "highest_score_job_dsc,_,__ = stratified_cross_validation(data_array_job, DecisionSetClassifier(number_nodes), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "Reached score: 0.2222222222222222\n",
      "found ruleset:\n",
      "[[1=0^3=0]]\n",
      "Reached score: 0.75\n",
      "found ruleset:\n",
      "[[3=0^6=1]]\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "[[5=1] V [0=1]]\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "[[5=1]]\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "[[6=1^5=1]]\n",
      "reached scores with 5 folds: [0.2222222222222222, 0.75, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "highest_score_job_ripper,_,__ = stratified_cross_validation(data_array_job, lw.RIPPER(), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tableizer_job1 = [f'full data set of shape {data_array_job.shape}; #folds=5', str(highest_score_job_dsc)+f' with {number_nodes} nodes', highest_score_job_ripper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using shortened data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array_job_shortened = data_array_job[:,2:]\n",
    "data_array_job_shortened = remove_duplicates(data_array_job_shortened)\n",
    "data_array_job_shortened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "+-----------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|         rules         | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+-----------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "| ¬1 ∧ ¬4 ∧ ¬3 → ¬class |                     0                     |                 0                 |       0.0       |\n",
      "|   ¬4 ∧ 1 ∧ 0 → class  |                     1                     |                 1                 |       1.0       |\n",
      "|    ¬0 ∧ 1 → ¬class    |                     1                     |                 1                 |       1.0       |\n",
      "|     4 ∧ ¬1 → class    |                     2                     |                 0                 |       0.0       |\n",
      "|       3 → class       |                     2                     |                 0                 |       0.0       |\n",
      "|  1 ∧ 4 ∧ ¬2 → ¬class  |                     0                     |                 0                 |       0.0       |\n",
      "+-----------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:530: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.6666666666666666\n",
      "found ruleset:\n",
      "+----------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|        rules         | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+----------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "| ¬4 ∧ ¬0 ∧ 2 → class  |                     0                     |                 0                 |       0.0       |\n",
      "|    4 ∧ 1 → ¬class    |                     2                     |                 1                 |       0.5       |\n",
      "| ¬4 ∧ 0 ∧ ¬3 → ¬class |                     1                     |                 1                 |       1.0       |\n",
      "|   ¬2 ∧ 1 → ¬class    |                     2                     |                 1                 |       0.5       |\n",
      "| ¬1 ∧ 4 ∧ ¬3 → class  |                     0                     |                 0                 |       0.0       |\n",
      "|      3 → class       |                     1                     |                 0                 |       0.0       |\n",
      "+----------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "reached scores with 5 folds: [None, 0.5, None, 0.6666666666666666, None]\n"
     ]
    }
   ],
   "source": [
    "number_nodes = 20 \n",
    "highest_score_job_shortened_dsc,_,__ = stratified_cross_validation(data_array_job_shortened, DecisionSetClassifier(number_nodes), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "Reached score: 0.75\n",
      "found ruleset:\n",
      "[[3=1]]\n",
      "Reached score: 0.75\n",
      "found ruleset:\n",
      "[[3=1]]\n",
      "Reached score: 0.75\n",
      "found ruleset:\n",
      "[[2=1]]\n",
      "Reached score: 0.3333333333333333\n",
      "found ruleset:\n",
      "[[1=0]]\n",
      "Reached score: 0.6666666666666666\n",
      "found ruleset:\n",
      "[[1=0]]\n",
      "reached scores with 5 folds: [0.75, 0.75, 0.75, 0.3333333333333333, 0.6666666666666666]\n"
     ]
    }
   ],
   "source": [
    "highest_score_job_shortened_ripper,_,__ = stratified_cross_validation(data_array_job_shortened, lw.RIPPER(), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tableizer_job2 = [f'shortened data set of shape {data_array_job_shortened.shape}; #folds=5', str(highest_score_job_shortened_dsc)+f' with {number_nodes} nodes', highest_score_job_shortened_ripper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum up results in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <caption>best accuracy scores for data set recuritment data set</caption>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>data set forms</th>\n",
       "            <th>our decsision set classifier</th>\n",
       "            <th>RIPPER</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>full data set of shape (41, 8); #folds=5</td>\n",
       "            <td>None with 29 nodes</td>\n",
       "            <td>0.75</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>shortened data set of shape (18, 6); #folds=5</td>\n",
       "            <td>0.6666666666666666 with 20 nodes</td>\n",
       "            <td>0.75</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------------------------------------------------------------------------------------------+\n",
       "|                   best accuracy scores for data set recuritment data set                  |\n",
       "+-----------------------------------------------+----------------------------------+--------+\n",
       "|                 data set forms                |   our decsision set classifier   | RIPPER |\n",
       "+-----------------------------------------------+----------------------------------+--------+\n",
       "|    full data set of shape (41, 8); #folds=5   |        None with 29 nodes        |  0.75  |\n",
       "| shortened data set of shape (18, 6); #folds=5 | 0.6666666666666666 with 20 nodes |  0.75  |\n",
       "+-----------------------------------------------+----------------------------------+--------+"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableizer('recuritment data set' ,list_tableizer_job1,list_tableizer_job2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**<br>\n",
    "-1: means that the problem was too complex for our decision set classifier. We can extend the recursion depth such that our classifier can make use of more computational ressources. This can be varied under: sys.setrecursionlimit(number)<br><br>\n",
    "None: means that our decision set classifier didn't find a model for our given data. A reason could be when training with small data sets and stratified cross validation, that there is indeed no pattern for which our classifier could find for a certain amount of rule nodes. We could increase the number of rule nodes 'number_nodes' (danger of too high complexity) and the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Working closer with the Mushroom data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.a. Convert the discrete data set into a binary one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>e</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>k</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7  8  9   ... 13 14 15 16 17 18 19 20 21 22\n",
       "0     p  x  s  n  t  p  f  c  n  k  ...  s  w  w  p  w  o  p  k  s  u\n",
       "1     e  x  s  y  t  a  f  c  b  k  ...  s  w  w  p  w  o  p  n  n  g\n",
       "2     e  b  s  w  t  l  f  c  b  n  ...  s  w  w  p  w  o  p  n  n  m\n",
       "3     p  x  y  w  t  p  f  c  n  n  ...  s  w  w  p  w  o  p  k  s  u\n",
       "4     e  x  s  g  f  n  f  w  b  k  ...  s  w  w  p  w  o  e  n  a  g\n",
       "...  .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. ..\n",
       "8119  e  k  s  n  f  n  a  c  b  y  ...  s  o  o  p  o  o  p  b  c  l\n",
       "8120  e  x  s  n  f  n  a  c  b  y  ...  s  o  o  p  n  o  p  b  v  l\n",
       "8121  e  f  s  n  f  n  a  c  b  n  ...  s  o  o  p  o  o  p  b  c  l\n",
       "8122  p  k  y  n  f  y  f  c  n  b  ...  k  w  w  p  w  o  e  w  v  l\n",
       "8123  e  x  s  n  f  n  a  c  b  y  ...  s  o  o  p  o  o  p  o  c  l\n",
       "\n",
       "[8124 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"datasets\") / Path(\"mushrooms\") / Path(\"agaricus-lepiota.data\")\n",
    "data_df = pd.read_csv(data_dir, sep=',', header=None)\n",
    "data_df.shape\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7  8  9   ... 13 14 15 16 17 18 19 20 21 22\n",
       "0     x  s  n  t  p  f  c  n  k  e  ...  w  w  p  w  o  p  k  s  u  0\n",
       "1     x  s  y  t  a  f  c  b  k  e  ...  w  w  p  w  o  p  n  n  g  1\n",
       "2     b  s  w  t  l  f  c  b  n  e  ...  w  w  p  w  o  p  n  n  m  1\n",
       "3     x  y  w  t  p  f  c  n  n  e  ...  w  w  p  w  o  p  k  s  u  0\n",
       "4     x  s  g  f  n  f  w  b  k  t  ...  w  w  p  w  o  e  n  a  g  1\n",
       "...  .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. ..\n",
       "8119  k  s  n  f  n  a  c  b  y  e  ...  o  o  p  o  o  p  b  c  l  1\n",
       "8120  x  s  n  f  n  a  c  b  y  e  ...  o  o  p  n  o  p  b  v  l  1\n",
       "8121  f  s  n  f  n  a  c  b  n  e  ...  o  o  p  o  o  p  b  c  l  1\n",
       "8122  k  y  n  f  y  f  c  n  b  t  ...  w  w  p  w  o  e  w  v  l  0\n",
       "8123  x  s  n  f  n  a  c  b  y  e  ...  o  o  p  o  o  p  o  c  l  1\n",
       "\n",
       "[8124 rows x 23 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['class'] = data_df[0].replace(['p','e'], [0,1]) # create a new column which is called 'class' and\n",
    "# below added as last column\n",
    "del data_df[0] # delete first column which orignially was the label column\n",
    "\n",
    "\n",
    "data_df.columns = [i for i in range(data_df.shape[1])] # rename columns by indexing\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total binary features: 117\n",
      "Discrete features attributes for each column/feature:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['f', 'k', 'x', 'c', 's', 'b'],\n",
       " ['y', 's', 'g', 'f'],\n",
       " ['p', 'c', 'b', 'n', 'g', 'r', 'w', 'u', 'y', 'e'],\n",
       " ['f', 't'],\n",
       " ['p', 'f', 'a', 'c', 'n', 's', 'l', 'y', 'm'],\n",
       " ['f', 'a'],\n",
       " ['w', 'c'],\n",
       " ['b', 'n'],\n",
       " ['o', 'p', 'k', 'n', 'g', 'r', 'y', 'w', 'h', 'u', 'b', 'e'],\n",
       " ['e', 't'],\n",
       " ['?', 'c', 'r', 'b', 'e'],\n",
       " ['y', 's', 'f', 'k'],\n",
       " ['y', 's', 'f', 'k'],\n",
       " ['o', 'p', 'c', 'n', 'g', 'y', 'w', 'b', 'e'],\n",
       " ['o', 'p', 'c', 'n', 'g', 'y', 'w', 'b', 'e'],\n",
       " ['p'],\n",
       " ['o', 'w', 'y', 'n'],\n",
       " ['o', 'n', 't'],\n",
       " ['p', 'f', 'n', 'l', 'e'],\n",
       " ['o', 'k', 'b', 'n', 'r', 'w', 'h', 'u', 'y'],\n",
       " ['a', 'c', 'n', 's', 'v', 'y'],\n",
       " ['p', 'd', 'g', 'w', 'l', 'u', 'm']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting all discrete feature attributes per column/feature:\n",
    "\n",
    "count_one_hot_features = 0\n",
    "nested_list = []\n",
    "\n",
    "for i in range(data_df.shape[1]-1): # -1 because we ignore the last column which describes the classes.\n",
    "    count_one_hot_features += len(set(data_df[i].values))\n",
    "    nested_list.append(list(set(data_df[i].values)))\n",
    "print('Number of total binary features:', count_one_hot_features) # column size of our one hot vector\n",
    "print('Discrete features attributes for each column/feature:')\n",
    "nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 118)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a binary feature data array which will be used for our decision set classifier:\n",
    "\n",
    "mushroom_arr = data_df.to_numpy()\n",
    "\n",
    "# create one-hot-vector representing the mushroom data set:\n",
    "one_hot_arr = np.zeros((mushroom_arr.shape[0],count_one_hot_features),dtype=int)\n",
    "\n",
    "start_ind = 0\n",
    "\n",
    "for col_ind, single_list in enumerate(nested_list):\n",
    "\n",
    "    for ind2, single_ele in enumerate(single_list):\n",
    "        \n",
    "        row_coordinates = np.where(mushroom_arr[:,col_ind] == single_ele)[0]\n",
    "        \n",
    "        col_mask = np.array([start_ind+ind2]*len(row_coordinates))\n",
    "        mask = (row_coordinates, col_mask)\n",
    "        one_hot_arr[mask] = 1\n",
    "        \n",
    "    start_ind = start_ind + len(single_list)\n",
    "    \n",
    "# Add the label column to the binary data array\n",
    "data_array_mush = np.append(one_hot_arr, mushroom_arr[:,-1].reshape(len(mushroom_arr[:,-1]),1), axis=1)\n",
    "data_array_mush.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.b. Try out the classifiers for full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number_nodes = 25\n",
    "#highest_score_mush_dsc,_,__ = stratified_cross_validation(data_array_mush, DecisionSetClassifier(number_nodes), number_folds=5)\n",
    "# problem too big --> kernel dies\n",
    "highest_score_mush_dsc = 'problem too complex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[26=1^49=0] V [90=1^54=0^22=0] V [26=1^99=0^35=1] V [33=1^25=0^105=0] V [91=1]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[26=1^49=0] V [90=1^54=0^22=0] V [26=1^108=0^33=0] V [33=1^25=0^105=0] V [26=1^62=1] V [89=1^99=0]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[26=1^49=0] V [90=1^54=0^22=0] V [26=1^108=0^33=0] V [33=1^25=0^105=0] V [26=1^62=1] V [89=1^99=0]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[26=1^49=0] V [90=1^54=0^22=0] V [26=1^99=0^60=0^16=0] V [33=1^49=0] V [26=1^109=1] V [91=1]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[26=1^49=0] V [90=1^54=0^22=0] V [26=1^99=0^60=0^16=0] V [33=1^49=0] V [26=1^109=1] V [91=1]]\n",
      "reached scores with 5 folds: [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "highest_score_mush_ripper,score_list_4b,rule_list_4b = stratified_cross_validation(data_array_mush, lw.RIPPER(), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tableizer_mush1 = [f'full data set of shape {data_array_mush.shape}; #folds=5', str(highest_score_mush_dsc)+f' with {number_nodes} nodes', highest_score_mush_ripper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.c. Use classifiers for reduced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 18)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array_short_mush = data_array_mush[:, 100:]\n",
    "data_array_short_mush = remove_duplicates(data_array_short_mush)\n",
    "data_array_short_mush.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "Reached score: None\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.7142857142857143\n",
      "found ruleset:\n",
      "+----------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|                 rules                  | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+----------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|    ¬2 ∧ ¬1 ∧ ¬15 ∧ ¬8 ∧ ¬11 → class    |                     4                     |                 1                 |       0.25      |\n",
      "|         ¬2 ∧ ¬14 ∧ 8 → ¬class          |                     1                     |                 0                 |       0.0       |\n",
      "|            7 ∧ 15 → ¬class             |                     0                     |                 0                 |       0.0       |\n",
      "| ¬0 ∧ ¬12 ∧ ¬10 ∧ ¬1 ∧ ¬7 ∧ ¬16 → class |                     1                     |                 0                 |       0.0       |\n",
      "|            5 ∧ 11 → ¬class             |                     0                     |                 0                 |       0.0       |\n",
      "|               1 → ¬class               |                     1                     |                 0                 |       0.0       |\n",
      "+----------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:530: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.5714285714285714\n",
      "found ruleset:\n",
      "+----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|           rules            | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|   7 ∧ ¬12 ∧ ¬16 → ¬class   |                     1                     |                 1                 |       1.0       |\n",
      "|         1 → ¬class         |                     1                     |                 0                 |       0.0       |\n",
      "|    ¬14 ∧ 0 ∧ ¬8 → class    |                     1                     |                 1                 |       1.0       |\n",
      "|   ¬2 ∧ ¬14 ∧ 8 → ¬class    |                     1                     |                 0                 |       0.0       |\n",
      "| ¬16 ∧ ¬7 ∧ ¬0 ∧ ¬1 → class |                     4                     |                 1                 |       0.25      |\n",
      "|      0 ∧ 14 → ¬class       |                     0                     |                 0                 |       0.0       |\n",
      "|      ¬8 ∧ 16 → class       |                     0                     |                 0                 |       0.0       |\n",
      "+----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.6666666666666666\n",
      "found ruleset:\n",
      "+----------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|                 rules                  | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+----------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|               1 → ¬class               |                     2                     |                 0                 |       0.0       |\n",
      "|            ¬14 ∧ 8 → ¬class            |                     1                     |                 1                 |       1.0       |\n",
      "|             5 ∧ 0 → ¬class             |                     1                     |                 1                 |       1.0       |\n",
      "|            14 ∧ ¬0 → class             |                     0                     |                 0                 |       0.0       |\n",
      "|            9 ∧ ¬10 → class             |                     1                     |                 1                 |       1.0       |\n",
      "|         7 ∧ ¬0 ∧ ¬10 → ¬class          |                     2                     |                 1                 |       0.5       |\n",
      "| ¬8 ∧ ¬2 ∧ ¬11 ∧ ¬15 ∧ ¬1 ∧ ¬14 → class |                     3                     |                 0                 |       0.0       |\n",
      "+----------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.6666666666666666\n",
      "found ruleset:\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|            rules            | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "| ¬14 ∧ ¬11 ∧ ¬1 ∧ ¬8 → class |                     4                     |                 1                 |       0.25      |\n",
      "|    ¬9 ∧ 11 ∧ ¬2 → ¬class    |                     0                     |                 0                 |       0.0       |\n",
      "|       ¬0 ∧ 14 → class       |                     0                     |                 0                 |       0.0       |\n",
      "|       12 ∧ 8 → ¬class       |                     0                     |                 0                 |       0.0       |\n",
      "|        11 ∧ 9 → class       |                     0                     |                 0                 |       0.0       |\n",
      "|          2 → class          |                     0                     |                 0                 |       0.0       |\n",
      "|          1 → ¬class         |                     1                     |                 0                 |       0.0       |\n",
      "|       0 ∧ 14 → ¬class       |                     0                     |                 0                 |       0.0       |\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "reached scores with 5 folds: [None, 0.7142857142857143, 0.5714285714285714, 0.6666666666666666, 0.6666666666666666]\n"
     ]
    }
   ],
   "source": [
    "number_nodes = 18 + 7 # here1\n",
    "highest_score_mush_short_dsc,_,__ = stratified_cross_validation(data_array_short_mush, DecisionSetClassifier(number_nodes), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "Reached score: 0.2857142857142857\n",
      "found ruleset:\n",
      "[[0=1]]\n",
      "Reached score: 0.7142857142857143\n",
      "found ruleset:\n",
      "[[8=0^1=0] V [14=1]]\n",
      "Reached score: 0.5714285714285714\n",
      "found ruleset:\n",
      "[[1=0^7=0^8=0]]\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "[[1=0^9=1] V [6=1]]\n",
      "Reached score: 0.6666666666666666\n",
      "found ruleset:\n",
      "[[1=0^9=1] V [1=0^11=0]]\n",
      "reached scores with 5 folds: [0.2857142857142857, 0.7142857142857143, 0.5714285714285714, 0.5, 0.6666666666666666]\n"
     ]
    }
   ],
   "source": [
    "highest_score_mush_short_ripper,ripper_score_list_short_mush,ripper_rule_list_short_mush = stratified_cross_validation(data_array_short_mush, lw.RIPPER(), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tableizer_mush2 = [f'shortened data set of shape {data_array_short_mush.shape}; #folds=5', str(highest_score_mush_short_dsc)+f' with {number_nodes} nodes', highest_score_mush_short_ripper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.d. Trying out if our decision set classifier can effectively learn from RIPPER's used features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... by directly using features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[26=1^49=0] V [90=1^54=0^22=0] V [26=1^99=0^35=1] V [33=1^25=0^105=0] V [91=1]]'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found ruleset of RIPPER for data_array_mush:\n",
    "index_highest_score = np.argmax(score_list_4b)\n",
    "ripper_best_ruleset = rule_list_4b[index_highest_score]\n",
    "ripper_best_ruleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F26=1F49=0] V F90=1F54=0F22=0] V F26=1F99=0F35=1] V F33=1F25=0F105=0] V F91=1]]'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate found rule nodes in ruleset by 'F':\n",
    "ripper_best_ruleset = ripper_best_ruleset.replace('[','F' )\n",
    "ripper_best_ruleset = ripper_best_ruleset.replace('^','F' )\n",
    "ripper_best_ruleset = ripper_best_ruleset[1:]\n",
    "ripper_best_ruleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 99, 35, 90, 105, 49, 54, 22, 25, 26, 91]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all features that were used:\n",
    "\n",
    "# Find all used features by finding out the index area between 'F' and '=':\n",
    "indices_of_binary_feat = [(m.start(0)) for m in re.finditer('F', ripper_best_ruleset)]\n",
    "indices_of_binary_feat2 = [(m.start(0)) for m in re.finditer('=', ripper_best_ruleset)]\n",
    "\n",
    "binary_feat_list = []\n",
    "\n",
    "for start, end in zip(indices_of_binary_feat,indices_of_binary_feat2):\n",
    "\n",
    "    binary_feat_list.append(int(ripper_best_ruleset[start+1:end]))\n",
    "    \n",
    "used_feat = list(set(binary_feat_list))\n",
    "\n",
    "# Count 'V'/the number of rules in the best ruleset:\n",
    "count = Counter(ripper_best_ruleset)\n",
    "number_rules = count['V']\n",
    "\n",
    "number_nodes = (len(binary_feat_list) + number_rules) + 2\n",
    "# we need to add number_rules because each rule contains\n",
    "# +2 because then our classifier finds model (see below)\n",
    "\n",
    "# a class node which is not listed in the given ruleset \n",
    "used_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's only consider these features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of mushroom data set: (8124, 118)\n",
      "Shape after only considering features used by best RIPPER: (23, 12)\n"
     ]
    }
   ],
   "source": [
    "# Convert data array to smaller one which only contains the features which were considered by RIPPER\n",
    "\n",
    "print('Original shape of mushroom data set:', data_array_mush.shape)\n",
    "\n",
    "# for indexing over data array:\n",
    "mask = np.array(used_feat)\n",
    "mask = np.append(mask, data_array_mush.shape[1]-1) # y-values/labels become part of the mask because we want to\n",
    "# get data array with them\n",
    "\n",
    "data_array_binary_mush = data_array_mush[:,mask]\n",
    "data_array_binary_mush = remove_duplicates(data_array_binary_mush)\n",
    "print('Shape after only considering features used by best RIPPER:', data_array_binary_mush.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the decision set classifier as stated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.2\n",
      "found ruleset:\n",
      "+-----------------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|                     rules                     | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+-----------------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "| ¬5 ∧ ¬5 ∧ ¬9 ∧ ¬2 ∧ ¬2 ∧ ¬5 ∧ ¬2 ∧ ¬4 → class |                     1                     |                 1                 |       1.0       |\n",
      "|              ¬7 ∧ ¬6 ∧ 3 → class              |                     0                     |                 0                 |       0.0       |\n",
      "|             ¬3 ∧ ¬10 ∧ ¬2 → ¬class            |                     2                     |                 1                 |       0.5       |\n",
      "|                   7 → ¬class                  |                     0                     |                 0                 |       0.0       |\n",
      "|                 2 ∧ 9 → class                 |                     2                     |                 1                 |       0.5       |\n",
      "|           ¬10 ∧ ¬2 ∧ 5 ∧ 0 → ¬class           |                     1                     |                 1                 |       1.0       |\n",
      "|              ¬0 ∧ ¬9 ∧ 6 → ¬class             |                     0                     |                 0                 |       0.0       |\n",
      "|                   10 → class                  |                     0                     |                 0                 |       0.0       |\n",
      "+-----------------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:530: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.6\n",
      "found ruleset:\n",
      "+---------------------------------+-------------------------------------------+-----------------------------------+--------------------+\n",
      "|              rules              | # test samples fulfilling rule conditions | # mistakenly fitting test samples |  % mistaken fits   |\n",
      "+---------------------------------+-------------------------------------------+-----------------------------------+--------------------+\n",
      "|            10 → class           |                     0                     |                 0                 |        0.0         |\n",
      "|          ¬3 ∧ 0 → class         |                     1                     |                 1                 |        1.0         |\n",
      "|     3 ∧ 5 ∧ ¬10 ∧ 6 → ¬class    |                     2                     |                 1                 |        0.5         |\n",
      "|        9 ∧ 3 ∧ ¬1 → class       |                     3                     |                 1                 | 0.3333333333333333 |\n",
      "| ¬4 ∧ 5 ∧ ¬10 ∧ ¬0 ∧ ¬3 → ¬class |                     0                     |                 0                 |        0.0         |\n",
      "|        2 ∧ 9 ∧ ¬1 → class       |                     2                     |                 0                 |        0.0         |\n",
      "|         ¬9 ∧ ¬3 → ¬class        |                     0                     |                 0                 |        0.0         |\n",
      "|          0 ∧ ¬5 → class         |                     0                     |                 0                 |        0.0         |\n",
      "|         ¬0 ∧ ¬9 → ¬class        |                     1                     |                 1                 |        1.0         |\n",
      "+---------------------------------+-------------------------------------------+-----------------------------------+--------------------+\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.2\n",
      "found ruleset:\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|            rules            | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|     3 ∧ ¬2 ∧ 0 → ¬class     |                     1                     |                 1                 |       1.0       |\n",
      "|         ¬5 → ¬class         |                     3                     |                 3                 |       1.0       |\n",
      "|     3 ∧ ¬6 ∧ ¬7 → class     |                     0                     |                 0                 |       0.0       |\n",
      "|        6 ∧ ¬3 → class       |                     1                     |                 1                 |       1.0       |\n",
      "|       ¬9 ∧ 4 → ¬class       |                     0                     |                 0                 |       0.0       |\n",
      "|          7 → ¬class         |                     0                     |                 0                 |       0.0       |\n",
      "| 2 ∧ 2 ∧ ¬1 ∧ ¬8 ∧ 9 → class |                     2                     |                 0                 |       0.0       |\n",
      "|          10 → class         |                     0                     |                 0                 |       0.0       |\n",
      "| ¬3 ∧ ¬10 ∧ ¬6 ∧ ¬2 → ¬class |                     0                     |                 0                 |       0.0       |\n",
      "|          1 → ¬class         |                     0                     |                 0                 |       0.0       |\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|            rules            | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|       ¬2 ∧ 4 → ¬class       |                     0                     |                 0                 |       0.0       |\n",
      "|       ¬3 ∧ ¬9 → ¬class      |                     0                     |                 0                 |       0.0       |\n",
      "|          1 → ¬class         |                     0                     |                 0                 |       0.0       |\n",
      "|  ¬2 ∧ ¬9 ∧ ¬4 ∧ ¬0 → ¬class |                     0                     |                 0                 |       0.0       |\n",
      "|     ¬6 ∧ 3 ∧ ¬7 → class     |                     2                     |                 0                 |       0.0       |\n",
      "|   ¬2 ∧ ¬8 ∧ ¬4 ∧ 6 → class  |                     0                     |                 0                 |       0.0       |\n",
      "| ¬4 ∧ ¬0 ∧ ¬3 ∧ ¬10 → ¬class |                     0                     |                 0                 |       0.0       |\n",
      "|          10 → class         |                     0                     |                 0                 |       0.0       |\n",
      "|      2 ∧ 9 ∧ ¬1 → class     |                     2                     |                 0                 |       0.0       |\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "+--------------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|                   rules                    | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+--------------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|              ¬9 ∧ ¬3 → ¬class              |                     0                     |                 0                 |       0.0       |\n",
      "|                 8 → ¬class                 |                     0                     |                 0                 |       0.0       |\n",
      "|               3 ∧ ¬6 → class               |                     2                     |                 1                 |       0.5       |\n",
      "|          6 ∧ ¬8 ∧ 0 ∧ ¬4 → class           |                     0                     |                 0                 |       0.0       |\n",
      "|          6 ∧ ¬1 ∧ ¬9 ∧ 2 → ¬class          |                     0                     |                 0                 |       0.0       |\n",
      "|             ¬1 ∧ 9 ∧ 2 → class             |                     0                     |                 0                 |       0.0       |\n",
      "| ¬2 ∧ ¬8 ∧ 0 ∧ 4 ∧ 0 ∧ ¬1 ∧ 0 ∧ ¬7 → ¬class |                     0                     |                 0                 |       0.0       |\n",
      "|                 1 → ¬class                 |                     0                     |                 0                 |       0.0       |\n",
      "+--------------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "reached scores with 5 folds: [0.2, 0.6, 0.2, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "number_nodes = number_nodes + 6\n",
    "highest_score_binary_mush_dsc,_,__ = stratified_cross_validation(data_array_binary_mush, DecisionSetClassifier(number_nodes), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "Reached score: 0.4\n",
      "found ruleset:\n",
      "[[3=1^9=1]]\n",
      "Reached score: 0.4\n",
      "found ruleset:\n",
      "[[9=1]]\n",
      "Reached score: 0.6\n",
      "found ruleset:\n",
      "[[2=1]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[3=1^6=0]]\n",
      "Reached score: 0.5\n",
      "found ruleset:\n",
      "[[2=1^1=0^3=1]]\n",
      "reached scores with 5 folds: [0.4, 0.4, 0.6, 1.0, 0.5]\n"
     ]
    }
   ],
   "source": [
    "highest_score_binary_mush_ripper,ripper_score_list_binary_mush,ripper_rule_list_binary_mush = stratified_cross_validation(data_array_binary_mush, lw.RIPPER(), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tableizer_mush3 = [f'shortened binary data set of shape {data_array_binary_mush.shape}; #folds=5', str(highest_score_binary_mush_dsc)+f' with {number_nodes} nodes', highest_score_binary_mush_ripper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIPPER reaches for the complete mushroom dataset of shape (8124, 118) an accuracy of 1 with kfold split of 2. When we ONLY use the found features for our decision set classifier it reaches only an accuracy of 0.42857142857142855. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... by finding out which discrete features where used (learning from whole disrecte features):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach will be more complicated for our decision set classifier than above because above one attribute is converted into one feature. However, here we have discrete features which can be handled by the RIPPER but our decision set classifier will get only the discrete features transformed to boolean values.That means our classifier has more options in learning something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 3, ..., 3, 5, 0],\n",
       "       [2, 1, 8, ..., 2, 2, 1],\n",
       "       [5, 1, 6, ..., 2, 6, 1],\n",
       "       ...,\n",
       "       [0, 1, 3, ..., 1, 4, 1],\n",
       "       [1, 0, 3, ..., 4, 4, 0],\n",
       "       [2, 1, 3, ..., 1, 4, 1]], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the objects of the mushroom data array into numeric discrete values:\n",
    "\n",
    "discrete_mushroom_arr2 = np.copy(mushroom_arr)\n",
    "discrete_mushroom_arr2.astype(str)\n",
    "\n",
    "discrete_mushroom_arr = np.copy(mushroom_arr)\n",
    "for column_index, column in enumerate(nested_list):\n",
    "    for index, attribute in enumerate(column):\n",
    "        mask = np.where(mushroom_arr[:,column_index] == attribute)\n",
    "        discrete_mushroom_arr[mask[0], column_index] = index\n",
    "        \n",
    "discrete_mushroom_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[4=4^9=1] V [18=0^7=0^9=0^17=0] V [4=4^10=0^7=0] V [4=4^3=0^11=1] V [6=0^9=1] V [4=4^21=0] V [4=4^11=2] V [11=0^2=3]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[4=4^9=1] V [18=0^7=0^9=0^17=0] V [4=4^10=0^7=0] V [4=4^3=0^11=1] V [6=0^9=1] V [4=4^19=5^10=3^3=0] V [17=2^19=5]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[4=4^9=1] V [18=0^10=1] V [4=4^10=0^7=0] V [18=0^12=0] V [4=4^10=4] V [6=0^9=1] V [4=4^12=2] V [4=4^21=0] V [4=4^14=3^6=0]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[4=4^9=1] V [18=0^7=0^9=0^17=0] V [4=4^10=0^7=0] V [4=4^3=0^11=1] V [6=0^9=1] V [4=4^21=0] V [4=4^14=3^10=3]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[4=4^9=1] V [18=0^7=0^9=0^17=0] V [4=4^10=0^7=0] V [4=4^3=0^11=1] V [6=0^9=1] V [4=4^21=0] V [4=4^11=2] V [11=0^2=3]]\n",
      "reached scores with 5 folds: [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Now RIPPER shall learn NOT from binary data set but from discrete one:\n",
    "highest_score_dis_mush_ripper,ripper_score_list_dis_mush,ripper_rule_list_dis_mush = stratified_cross_validation(discrete_mushroom_arr, lw.RIPPER(), number_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see all used features to end up with a positive class prediction, the important attribute values and number of nodes.<br>\n",
    "Take the best performing rule set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[4=4^9=1] V [18=0^7=0^9=0^17=0] V [4=4^10=0^7=0] V [4=4^3=0^11=1] V [6=0^9=1] V [4=4^21=0] V [4=4^11=2] V [11=0^2=3]]'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_highest_score = np.argmax(ripper_score_list_dis_mush)\n",
    "ripper_best_ruleset = ripper_rule_list_dis_mush[index_highest_score]\n",
    "ripper_best_ruleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F4=4F9=1] V F18=0F7=0F9=0F17=0] V F4=4F10=0F7=0] V F4=4F3=0F11=1] V F6=0F9=1] V F4=4F21=0] V F4=4F11=2] V F11=0F2=3]]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripper_best_ruleset = ripper_best_ruleset.replace('[','F' )\n",
    "ripper_best_ruleset = ripper_best_ruleset.replace('^','F' )\n",
    "ripper_best_ruleset = ripper_best_ruleset[1:]\n",
    "ripper_best_ruleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 6, 7, 9, 10, 11, 17, 18, 21]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all features that were used:\n",
    "\n",
    "indices_of_discrete_feat = [(m.start(0)) for m in re.finditer('F', ripper_best_ruleset)]\n",
    "indices_of_discrete_feat2 = [(m.start(0)) for m in re.finditer('=', ripper_best_ruleset)]\n",
    "\n",
    "discrete_feat_list = []\n",
    "\n",
    "for start, end in zip(indices_of_discrete_feat,indices_of_discrete_feat2):\n",
    "\n",
    "    discrete_feat_list.append(int(ripper_best_ruleset[start+1:end]))\n",
    "\n",
    "used_feat = list(set(discrete_feat_list))\n",
    "\n",
    "# Count 'V'/the number of rules in the best ruleset:\n",
    "count = Counter(ripper_best_ruleset)\n",
    "number_rules = count['V']\n",
    "\n",
    "number_nodes = len(discrete_feat_list) + number_rules\n",
    "used_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half of the features where used. <br>\n",
    "Let's come to our decision set classifier. Transfer the used features into one hot encoding for binary usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mushroom data set shape: (8124, 23)\n",
      "Shape only considering the discrete features used by RIPPER: (130, 52)\n"
     ]
    }
   ],
   "source": [
    "# Only find out the feature attributes for the used discrete features by RIPPER:\n",
    "# Reason: Our decision set classifier shall later only look at that used features but can only do this\n",
    "# for binary ones. Therefore, we transfer discrete features into binary features\n",
    "\n",
    "count_one_hot_features = 0\n",
    "nested_list_updated = []\n",
    "for index in used_feat:\n",
    "    used = nested_list[index] # nested list with attribute values of each feature which where used by RIPPER\n",
    "    count_one_hot_features += len(used)\n",
    "    nested_list_updated.append(used)\n",
    "\n",
    "\n",
    "# create one-hot-vector representing the mushroom data set:\n",
    "\n",
    "one_hot_arr = np.zeros((mushroom_arr.shape[0], count_one_hot_features),dtype=int)\n",
    "\n",
    "start_ind = 0\n",
    "for col_ind, single_list in zip(used_feat, nested_list_updated):\n",
    "    for ind2, single_ele in enumerate(single_list):\n",
    "        row_coordinates = np.where(mushroom_arr[:,col_ind] == single_ele)[0]\n",
    "        \n",
    "        col_mask = np.array([start_ind+ind2]*len(row_coordinates))\n",
    "        mask = (row_coordinates, col_mask)\n",
    "        one_hot_arr[mask] = 1\n",
    "    start_ind = start_ind + len(single_list)\n",
    "    \n",
    "# Create the data set with selected features:\n",
    "data_array_with_y_discrete_mush = np.append(one_hot_arr, mushroom_arr[:,-1].reshape(len(mushroom_arr[:,-1]),1), axis=1)\n",
    "data_array_discrete_mush = remove_duplicates(data_array_with_y_discrete_mush)\n",
    "\n",
    "print('Original mushroom data set shape:', mushroom_arr.shape)\n",
    "print('Shape only considering the discrete features used by RIPPER:', data_array_discrete_mush.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the decision set classifier as stated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "Reached score: -1\n",
      "found ruleset:\n",
      "None\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.9615384615384616\n",
      "found ruleset:\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+---------------------+\n",
      "|            rules            | # test samples fulfilling rule conditions | # mistakenly fitting test samples |   % mistaken fits   |\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+---------------------+\n",
      "|          18 → class         |                     4                     |                 0                 |         0.0         |\n",
      "|      50 ∧ ¬28 → ¬class      |                     0                     |                 0                 |         0.0         |\n",
      "|       46 ∧ 30 → ¬class      |                     3                     |                 0                 |         0.0         |\n",
      "|         13 → ¬class         |                     5                     |                 0                 |         0.0         |\n",
      "|     ¬8 ∧ 10 ∧ 16 → class    |                     6                     |                 1                 | 0.16666666666666666 |\n",
      "|      ¬16 ∧ ¬11 → ¬class     |                     9                     |                 0                 |         0.0         |\n",
      "|          14 → class         |                     2                     |                 0                 |         0.0         |\n",
      "| 16 ∧ ¬46 ∧ 23 ∧ ¬50 → class |                     1                     |                 0                 |         0.0         |\n",
      "|       16 ∧ 8 → ¬class       |                     0                     |                 0                 |         0.0         |\n",
      "|    ¬10 ∧ 24 ∧ 25 → ¬class   |                     2                     |                 0                 |         0.0         |\n",
      "|         17 → ¬class         |                     1                     |                 0                 |         0.0         |\n",
      "+-----------------------------+-------------------------------------------+-----------------------------------+---------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:530: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.9615384615384616\n",
      "found ruleset:\n",
      "+------------------------------------------------+-------------------------------------------+-----------------------------------+--------------------+\n",
      "|                     rules                      | # test samples fulfilling rule conditions | # mistakenly fitting test samples |  % mistaken fits   |\n",
      "+------------------------------------------------+-------------------------------------------+-----------------------------------+--------------------+\n",
      "|                  12 → ¬class                   |                     0                     |                 0                 |        0.0         |\n",
      "|                ¬25 ∧ 21 → class                |                     2                     |                 0                 |        0.0         |\n",
      "|       24 ∧ 36 ∧ ¬49 ∧ ¬40 ∧ 22 → ¬class        |                     9                     |                 0                 |        0.0         |\n",
      "|         30 ∧ ¬44 ∧ ¬45 ∧ ¬10 → ¬class          |                     4                     |                 0                 |        0.0         |\n",
      "|          ¬35 ∧ ¬46 ∧ ¬50 ∧ 16 → class          |                     7                     |                 2                 | 0.2857142857142857 |\n",
      "|            ¬48 ∧ ¬16 ∧ ¬11 → ¬class            |                     5                     |                 0                 |        0.0         |\n",
      "| ¬0 ∧ ¬34 ∧ ¬41 ∧ ¬24 ∧ ¬30 ∧ ¬17 ∧ ¬12 → class |                     4                     |                 0                 |        0.0         |\n",
      "+------------------------------------------------+-------------------------------------------+-----------------------------------+--------------------+\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "Reached score: 0.9615384615384616\n",
      "found ruleset:\n",
      "+-----------------------------------------------------------+-------------------------------------------+-----------------------------------+---------------------+\n",
      "|                           rules                           | # test samples fulfilling rule conditions | # mistakenly fitting test samples |   % mistaken fits   |\n",
      "+-----------------------------------------------------------+-------------------------------------------+-----------------------------------+---------------------+\n",
      "|                         40 → class                        |                     1                     |                 0                 |         0.0         |\n",
      "|                         18 → class                        |                     0                     |                 0                 |         0.0         |\n",
      "| ¬12 ∧ ¬2 ∧ ¬15 ∧ ¬28 ∧ ¬50 ∧ ¬13 ∧ ¬18 ∧ ¬6 ∧ ¬27 → class |                     6                     |                 1                 | 0.16666666666666666 |\n",
      "|               ¬17 ∧ ¬45 ∧ ¬24 ∧ ¬30 → class               |                     5                     |                 0                 |         0.0         |\n",
      "|         ¬44 ∧ ¬18 ∧ ¬43 ∧ ¬45 ∧ ¬14 ∧ ¬10 → ¬class        |                     4                     |                 0                 |         0.0         |\n",
      "|                  ¬30 ∧ ¬23 ∧ 43 → ¬class                  |                     10                    |                 0                 |         0.0         |\n",
      "|                     ¬16 ∧ 10 → ¬class                     |                     11                    |                 0                 |         0.0         |\n",
      "+-----------------------------------------------------------+-------------------------------------------+-----------------------------------+---------------------+\n",
      "CONSTRAINT 1 done\n",
      "CONSTRAINT 2 done\n",
      "CONSTRAINT 3 done\n",
      "CONSTRAINT 4 done\n",
      "CONSTRAINT 5 done\n",
      "CONSTRAINT 6 done\n",
      "final string done\n",
      "expressing string done\n",
      "tseitin transformation done\n",
      "dimacs conversion done\n",
      "finding model done\n",
      "no sample for our rule fitting\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "+------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "|               rules                | # test samples fulfilling rule conditions | # mistakenly fitting test samples | % mistaken fits |\n",
      "+------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "| ¬35 ∧ ¬28 ∧ ¬15 ∧ 25 ∧ ¬11 → class |                     3                     |                 0                 |       0.0       |\n",
      "| ¬1 ∧ ¬26 ∧ ¬3 ∧ 30 ∧ ¬44 → ¬class  |                     4                     |                 0                 |       0.0       |\n",
      "|       24 ∧ 43 ∧ ¬30 → ¬class       |                     6                     |                 0                 |       0.0       |\n",
      "|          44 ∧ 38 → class           |                     3                     |                 0                 |       0.0       |\n",
      "|          27 ∧ ¬24 → class          |                     4                     |                 0                 |       0.0       |\n",
      "|             14 → class             |                     0                     |                 0                 |       0.0       |\n",
      "|      ¬16 ∧ ¬18 ∧ ¬14 → ¬class      |                     16                    |                 0                 |       0.0       |\n",
      "|             18 → class             |                     1                     |                 0                 |       0.0       |\n",
      "|          16 ∧ 26 → class           |                     1                     |                 0                 |       0.0       |\n",
      "+------------------------------------+-------------------------------------------+-----------------------------------+-----------------+\n",
      "reached scores with 5 folds: [-1, 0.9615384615384616, 0.9615384615384616, 0.9615384615384616, 1.0]\n"
     ]
    }
   ],
   "source": [
    "number_nodes = number_nodes\n",
    "highest_score_dis_mush_dsc,_,__ = stratified_cross_validation(data_array_discrete_mush, DecisionSetClassifier(number_nodes), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT FORGET TO CHANGE THE ARGUMENT path_to_kissat_solver. This leads us to the storage place of KISSAT\n",
      "Reached score: 0.9615384615384616\n",
      "found ruleset:\n",
      "[[16=1^21=1] V [10=0^14=1] V [16=1^44=1] V [16=1^47=1] V [18=1] V [16=1^10=1]]\n",
      "Reached score: 0.8846153846153846\n",
      "found ruleset:\n",
      "[[16=1^30=0^8=0] V [10=0^13=0^36=1] V [16=1^46=0^8=0^50=0]]\n",
      "Reached score: 0.8461538461538461\n",
      "found ruleset:\n",
      "[[16=1^21=1] V [10=0^30=0^12=0] V [16=1] V [14=1] V [18=1]]\n",
      "Reached score: 0.8846153846153846\n",
      "found ruleset:\n",
      "[[23=1^30=0] V [16=1^46=0^30=1^50=0] V [18=1] V [14=1]]\n",
      "Reached score: 1.0\n",
      "found ruleset:\n",
      "[[16=1^10=1] V [10=0^49=0^46=0] V [18=1] V [14=1]]\n",
      "reached scores with 5 folds: [0.9615384615384616, 0.8846153846153846, 0.8461538461538461, 0.8846153846153846, 1.0]\n"
     ]
    }
   ],
   "source": [
    "highest_score_dis_mush_ripper,_,__ = stratified_cross_validation(data_array_discrete_mush, lw.RIPPER(), number_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tableizer_mush4 = [f'shortened discrete data set of shape {data_array_discrete_mush.shape}; #folds=5', str(highest_score_dis_mush_dsc)+f' with {number_nodes} nodes', highest_score_dis_mush_ripper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final table for the mushroom data set. Having a look how good each classifier performed (accuracy) on each condition (data set manipulation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <caption>best accuracy scores for data set mushroom data set</caption>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>data set forms</th>\n",
       "            <th>our decsision set classifier</th>\n",
       "            <th>RIPPER</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>full data set of shape (8124, 118); #folds=5</td>\n",
       "            <td>problem too complex with 20 nodes</td>\n",
       "            <td>1.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>shortened data set of shape (33, 18); #folds=5</td>\n",
       "            <td>0.7142857142857143 with 25 nodes</td>\n",
       "            <td>0.7142857142857143</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>shortened binary data set of shape (23, 12); #folds=5</td>\n",
       "            <td>0.6 with 33 nodes</td>\n",
       "            <td>1.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>shortened discrete data set of shape (130, 52); #folds=5</td>\n",
       "            <td>1.0 with 33 nodes</td>\n",
       "            <td>1.0</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------------------------------------------------------------------------------------------------------------------+\n",
       "|                                best accuracy scores for data set mushroom data set                                |\n",
       "+----------------------------------------------------------+-----------------------------------+--------------------+\n",
       "|                      data set forms                      |    our decsision set classifier   |       RIPPER       |\n",
       "+----------------------------------------------------------+-----------------------------------+--------------------+\n",
       "|       full data set of shape (8124, 118); #folds=5       | problem too complex with 20 nodes |        1.0         |\n",
       "|      shortened data set of shape (33, 18); #folds=5      |  0.7142857142857143 with 25 nodes | 0.7142857142857143 |\n",
       "|  shortened binary data set of shape (23, 12); #folds=5   |         0.6 with 33 nodes         |        1.0         |\n",
       "| shortened discrete data set of shape (130, 52); #folds=5 |         1.0 with 33 nodes         |        1.0         |\n",
       "+----------------------------------------------------------+-----------------------------------+--------------------+"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableizer('mushroom data set' ,list_tableizer_mush1,list_tableizer_mush2,list_tableizer_mush3,list_tableizer_mush4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**<br>\n",
    "-1: means that the problem was too complex for our decision set classifier. We can extend the recursion depth such that our classifier can make use of more computational ressources. This can be varied under: sys.setrecursionlimit(number)<br><br>\n",
    "None: means that our decision set classifier didn't find a model for our given data. A reason could be when training with small data sets and stratified cross validation, that there is indeed no pattern for which our classifier could find for a certain amount of rule nodes. We could increase the number of rule nodes 'number_nodes' and the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIPPER outperforms our implemented decision set classifier 'opt' for the given data sets. Furthermore, it is much faster. One more problem is the scalability of our opt. It struggles with handling high data amounts. Nevertheless, the loops (which lead to heavy and long computations for the final SAT solver) are unavoidable according to one of the authors. <br>\n",
    "However, the opt was only the starting classifier in the underlying paper \"Computing Optimal Decision Sets with SAT\" (Yu et al., 2020). It would be interesting to see the performance of further going classifiers from the paper which also include soft constraints. These constraints allow us a to lower the accuracy to less than 1 on the training set such that the model wouldn't need a 100 % fit to training data.<br>\n",
    "In conclusion, this work gave me a good insight in working with a decision set concept of which I had never heard before. It is an interesting alternative apporach of working with data in the field of AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
